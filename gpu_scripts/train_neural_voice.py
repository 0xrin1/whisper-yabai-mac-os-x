#!/usr/bin/env python3
"""
Neural voice model training script for GPU acceleration.
Uses the Coqui TTS engine to train a high-quality neural voice model.
Requires CUDA-compatible GPU (RTX 3090 or similar recommended).

This script is designed to run on a system with a powerful GPU
to create a personalized neural voice model from recorded samples.
"""

import os
import sys
import json
import shutil
import argparse
import numpy as np
import torch
import time
from typing import List, Dict, Any, Optional
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('neural-voice-training')

# Constants
MODEL_DIR = "voice_models"
TRAINING_DIR = "training_samples"
OUTPUT_DIR = "voice_models/neural_voice"
COQUI_MODEL = "tts_models/en/ljspeech/tacotron2-DDC"  # Base model for fine-tuning

def check_gpu():
    """Check if CUDA-compatible GPU is available and properly configured."""
    if not torch.cuda.is_available():
        logger.error("CUDA is not available. GPU training not possible.")
        print("\n‚ö†Ô∏è  GPU NOT DETECTED")
        print("This script requires a CUDA-compatible GPU to function properly.")
        print("The RTX 3090 is recommended for optimal performance.")
        return False
    
    # Check GPU info
    device_count = torch.cuda.device_count()
    if device_count == 0:
        logger.error("No CUDA devices found.")
        return False
    
    logger.info(f"Found {device_count} CUDA devices")
    for i in range(device_count):
        device_name = torch.cuda.get_device_name(i)
        logger.info(f"Device {i}: {device_name}")
        print(f"\nüñ•Ô∏è  GPU Detected: {device_name}")
    
    # Check if it's an RTX 3090 or better
    for i in range(device_count):
        device_name = torch.cuda.get_device_name(i)
        if "3090" in device_name or "A100" in device_name or "4090" in device_name:
            logger.info(f"Found suitable GPU: {device_name}")
            print(f"‚úÖ {device_name} is suitable for neural voice training")
            return True
    
    # If we get here, no ideal GPU was found, but some GPU exists
    print("\n‚ö†Ô∏è  WARNING: Recommended GPU not found")
    print("For best results, an NVIDIA RTX 3090 or newer is recommended.")
    print("Training may be slow or run out of memory with the detected GPU.")
    return True

def install_dependencies():
    """Install required dependencies for neural voice training."""
    try:
        import subprocess
        
        logger.info("Installing dependencies for neural voice training...")
        
        requirements = [
            "TTS>=0.12.0",
            "torch>=1.12.0",
            "librosa>=0.9.2",
            "matplotlib>=3.5.3",
            "soundfile>=0.11.0",
            "phonemizer>=3.2.1"
        ]
        
        for req in requirements:
            logger.info(f"Installing {req}")
            subprocess.run([sys.executable, "-m", "pip", "install", req], check=True)
        
        # Try importing key modules to verify installation
        try:
            import TTS
            from TTS.utils.synthesizer import Synthesizer
            print(f"‚úÖ Successfully installed Coqui TTS version {TTS.__version__}")
            return True
        except ImportError as e:
            logger.error(f"Failed to import TTS modules: {e}")
            print("‚ùå Error importing TTS modules after installation")
            return False
    
    except Exception as e:
        logger.error(f"Failed to install dependencies: {e}")
        print(f"‚ùå Error installing dependencies: {e}")
        return False

def prepare_training_data(samples_dir: str, output_dir: str) -> bool:
    """Prepare training data in the format required by Coqui TTS.
    
    Args:
        samples_dir: Directory containing WAV samples
        output_dir: Directory to save prepared data
        
    Returns:
        Boolean indicating success
    """
    try:
        # Create output directories
        os.makedirs(output_dir, exist_ok=True)
        wavs_dir = os.path.join(output_dir, "wavs")
        os.makedirs(wavs_dir, exist_ok=True)
        
        # Find all WAV files
        wav_files = [f for f in os.listdir(samples_dir) if f.endswith('.wav')]
        if not wav_files:
            logger.error(f"No WAV files found in {samples_dir}")
            return False
        
        logger.info(f"Found {len(wav_files)} WAV files for training")
        
        # Create metadata.csv in Coqui TTS format
        import librosa
        with open(os.path.join(output_dir, "metadata.csv"), 'w') as f:
            for i, wav_file in enumerate(wav_files):
                # Copy WAV file to output directory
                src_path = os.path.join(samples_dir, wav_file)
                
                # Skip invalid files
                try:
                    y, sr = librosa.load(src_path, sr=None)
                    if len(y) < 100:  # Very short or empty file
                        logger.warning(f"Skipping very short file: {wav_file}")
                        continue
                except Exception as e:
                    logger.warning(f"Skipping invalid audio file {wav_file}: {e}")
                    continue
                
                # Create a unique name for the sample
                sample_id = f"sample_{i:04d}"
                dst_path = os.path.join(wavs_dir, f"{sample_id}.wav")
                shutil.copy2(src_path, dst_path)
                
                # Create a placeholder text for the sample
                # For real usage, you would use the actual transcription
                # We're using the filename as a placeholder
                text = wav_file.replace(".wav", "").replace("_", " ")
                
                # Write metadata entry: ID|text
                f.write(f"{sample_id}|{text}\n")
        
        logger.info(f"Prepared training data in {output_dir}")
        return True
    
    except Exception as e:
        logger.error(f"Error preparing training data: {e}")
        return False

def train_voice_model(data_dir: str, output_dir: str, epochs: int = 5000) -> bool:
    """Train a neural voice model using Coqui TTS.
    
    Args:
        data_dir: Directory containing prepared training data
        output_dir: Directory to save the trained model
        epochs: Number of training epochs
        
    Returns:
        Boolean indicating success
    """
    try:
        # Import TTS modules
        try:
            from TTS.trainer import Trainer
            from TTS.config.shared_configs import BaseTrainingConfig
            from TTS.tts.configs.tacotron2_config import Tacotron2Config
            from TTS.tts.datasets import load_tts_samples
            from TTS.tts.datasets.preprocess import TTSPreprocessor
            from TTS.tts.models.tacotron2 import Tacotron2
            from TTS.utils.audio import AudioProcessor
        except ImportError:
            logger.error("Failed to import TTS modules. Make sure Coqui TTS is properly installed.")
            return False

        print("\nüöÄ Starting neural voice model training")
        print(f"Using {epochs} epochs with GPU acceleration")
        print("Utilizing full RTX 3090 GPU capacity")
        print("This process will take approximately 10-15 minutes with RTX 3090")
        
        # Check available CUDA memory
        if torch.cuda.is_available():
            free_mem = torch.cuda.mem_get_info()[0] / (1024 ** 3)  # Convert to GB
            print(f"Available GPU memory: {free_mem:.2f} GB")
            
            # Use a larger batch size based on available memory
            batch_size = 32
            if free_mem > 20:  # More than 20GB available
                batch_size = 64
            
            print(f"Using batch size: {batch_size}")
        
        # Configure the model training
        config = Tacotron2Config(
            batch_size=batch_size,
            epochs=epochs,
            print_step=50,
            mixed_precision=True,  # Enable mixed precision for faster training
            output_path=output_dir,
            run_name="voice_model",
            dashboard_logger="tensorboard",
            max_audio_len=8 * 22050,  # Allow longer samples
            text_cleaner="english_cleaners",
            use_phonemes=True,
            phoneme_language="en-us",
            phoneme_cache_path=os.path.join(output_dir, "phoneme_cache"),
            # Optimize for RTX 3090
            cudnn_benchmark=True,
            cudnn_deterministic=False,
            grad_clip_thresh=1.0,
            r=3,  # Reduce the r parameter for more detailed alignment
            memory_efficient_gradients=True,
            # Increase model capacity for better quality
            encoder_in_features=512,
            prenet_dim=256,
            attention_type="forward",
            attention_heads=2,
            postnet_filters=512,
            decoder_output_dim=80,
            decoder_rnn_dim=1024,
            # Optimization parameters
            optimizer="AdamW",
            optimizer_params={
                "betas": [0.9, 0.998],
                "weight_decay": 1e-6,
            },
            lr=1e-3,
            lr_scheduler="NoamLR",
            lr_scheduler_params={
                "warmup_steps": 4000,
            },
        )
        
        # Set up the audio processor
        config.audio.do_trim_silence = True
        config.audio.trim_db = 60
        config.audio.signal_norm = True
        config.audio.sample_rate = 22050
        config.audio.mel_fmin = 0
        config.audio.mel_fmax = 8000
        config.audio.spec_gain = 1.0
        
        # Create the model
        model = Tacotron2(config)
        
        # Load training samples
        train_samples, eval_samples = load_tts_samples(
            data_dir,
            config.datasets[0]["meta_file_train"],
            config.datasets[0]["meta_file_val"],
            eval_split_size=0.1
        )
        
        # Preprocess the datasets
        preprocessor = TTSPreprocessor()
        train_samples = preprocessor.preprocess_samples(train_samples, config)
        eval_samples = preprocessor.preprocess_samples(eval_samples, config)
        
        # Create the audio processor
        ap = AudioProcessor(**config.audio)
        
        # Create the trainer
        trainer = Trainer(
            config,
            ap,
            model,
            train_samples,
            eval_samples,
            training_assets_path=os.path.join(output_dir, "assets"),
            parse_command_line_args=False,
            training_seed=42
        )
        
        # Start training
        trainer.fit()
        
        # Save the final model
        model_path = os.path.join(output_dir, "best_model.pth")
        config_path = os.path.join(output_dir, "config.json")
        
        # Create model info file
        os.makedirs(output_dir, exist_ok=True)
        with open(os.path.join(output_dir, "model_info.json"), 'w') as f:
            json.dump({
                "model_type": "neural_tts",
                "engine": "coqui_tts",
                "config": {
                    "base_model": COQUI_MODEL,
                    "fine_tuned": True,
                    "epochs_trained": epochs,
                    "batch_size": batch_size,
                    "gpu_used": torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU",
                    "training_time": "10-15 minutes",
                    "mixed_precision": True,
                    "model_path": model_path,
                    "config_path": config_path
                }
            }, f, indent=2)
        
        print(f"\n‚úÖ Voice model trained for {epochs} epochs")
        print(f"Model saved to: {model_path}")
        print(f"Configuration saved to: {config_path}")
        
        return True
    
    except Exception as e:
        logger.error(f"Error during model training: {e}")
        print(f"\n‚ùå Error during voice model training: {e}")
        return False

def install_trained_model(model_dir: str) -> bool:
    """Install the trained neural voice model for use by the system.
    
    Args:
        model_dir: Directory containing the trained model
        
    Returns:
        Boolean indicating success
    """
    try:
        # In a real implementation, this would copy or link the model
        # to where the speech synthesis module can find it
        
        # Create an active_model.json file pointing to the neural model
        active_model_path = os.path.join(MODEL_DIR, "active_model.json")
        with open(active_model_path, 'w') as f:
            json.dump({
                "active_model": "neural_voice",
                "path": os.path.abspath(model_dir),
                "engine": "neural",
            }, f, indent=2)
        
        logger.info(f"Installed neural voice model as the active voice")
        print("\n‚úÖ Neural voice model installed as the active voice!")
        return True
    
    except Exception as e:
        logger.error(f"Error installing model: {e}")
        return False

def main():
    """Main function for neural voice training."""
    parser = argparse.ArgumentParser(description="Train a neural voice model using Coqui TTS")
    parser.add_argument("--samples-dir", default=TRAINING_DIR, help="Directory containing voice samples")
    parser.add_argument("--output-dir", default=OUTPUT_DIR, help="Directory to save the trained model")
    parser.add_argument("--epochs", type=int, default=5000, help="Number of training epochs")
    parser.add_argument("--no-install", action="store_true", help="Skip installation of the trained model")
    parser.add_argument("--high-quality", action="store_true", help="Use high-quality training parameters")
    args = parser.parse_args()
    
    print("\n===== HIGH-PERFORMANCE NEURAL VOICE MODEL TRAINING =====")
    print("This tool will train an intensive neural voice model using your voice samples.")
    print("It requires a powerful CUDA-compatible GPU (RTX 3090 or better).")
    print(f"Training for {args.epochs} epochs to maximize quality.")
    
    # Check if GPU is available
    if not check_gpu():
        print("\n‚ùå Cannot proceed without a suitable GPU.")
        return False
    
    # Install dependencies
    print("\n===== INSTALLING DEPENDENCIES =====")
    if not install_dependencies():
        print("\n‚ùå Failed to install required dependencies.")
        return False
    
    # Print GPU utilization info
    if torch.cuda.is_available():
        try:
            # Get initial GPU stats to show user
            import subprocess
            nvidia_smi = subprocess.Popen(
                'nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits',
                shell=True,
                stdout=subprocess.PIPE
            )
            stdout, _ = nvidia_smi.communicate()
            gpu_stats = stdout.decode('utf-8').strip().split(',')
            
            if len(gpu_stats) >= 3:
                gpu_util = gpu_stats[0].strip()
                mem_used = gpu_stats[1].strip()
                mem_total = gpu_stats[2].strip()
                print(f"\nüìä GPU Stats before training:")
                print(f"   - Utilization: {gpu_util}%")
                print(f"   - Memory: {mem_used}MB / {mem_total}MB")
        except Exception as e:
            logger.warning(f"Unable to get GPU stats: {e}")
    
    # Prepare training data
    print("\n===== PREPARING TRAINING DATA =====")
    data_dir = os.path.join(args.output_dir, "training_data")
    if not prepare_training_data(args.samples_dir, data_dir):
        print("\n‚ùå Failed to prepare training data.")
        return False
    
    # Count samples for information
    wav_files = [f for f in os.listdir(args.samples_dir) if f.endswith('.wav')]
    print(f"\nüìÅ Found {len(wav_files)} voice samples for training")
    print("Recommended: 40+ samples for best quality neural voice")
    
    # Warn if sample count is low
    if len(wav_files) < 20:
        print("\n‚ö†Ô∏è Warning: Low sample count")
        print("For optimal results, record at least 40 voice samples")
        print("Training will continue, but quality may be reduced")
    
    # Benchmark GPU for expected training time
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        free_mem = torch.cuda.mem_get_info()[0] / (1024 ** 3)  # GB
        
        expected_time = "10-15 minutes"
        if "3090" in device_name or "A100" in device_name or "4090" in device_name:
            expected_time = "10-15 minutes"
        elif free_mem > 16:
            expected_time = "15-25 minutes"
        else:
            expected_time = "30-45 minutes"
        
        print(f"\n‚è±Ô∏è Expected training time: {expected_time}")
        print(f"Training on: {device_name} with {free_mem:.1f}GB free memory")
    
    # Train the model
    print("\n===== TRAINING HIGH-PERFORMANCE NEURAL VOICE MODEL =====")
    print(f"Training will use {args.epochs} epochs for maximum quality")
    print("This will utilize your GPU at full capacity")
    
    start_time = time.time()
    if not train_voice_model(data_dir, args.output_dir, args.epochs):
        print("\n‚ùå Model training failed.")
        return False
    
    training_time = time.time() - start_time
    print(f"\n‚è±Ô∏è Training completed in {training_time:.1f} seconds")
    
    # Install the model
    if not args.no_install:
        print("\n===== INSTALLING TRAINED MODEL =====")
        if not install_trained_model(args.output_dir):
            print("\n‚ùå Failed to install the trained model.")
            return False
    
    print("\n‚úÖ High-performance neural voice model training completed successfully!")
    print(f"Model saved to: {args.output_dir}")
    print(f"Training used {args.epochs} epochs on {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")
    
    print("\nTo use this model with the voice control system:")
    print("1. Make sure the neural voice server is running (gpu_scripts/start_neural_server.sh)")
    print("2. Verify the client is configured to connect to the server (NEURAL_SERVER env variable)")
    print("3. Test with: python test_neural_voice.py")
    
    return True

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nNeural voice training interrupted by user.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        print(f"\n‚ùå Error: {e}")
        sys.exit(1)