#!/usr/bin/env python3
"""
Neural voice model training script for GPU acceleration.
Uses the Coqui TTS engine to train a high-quality neural voice model.
Requires CUDA-compatible GPU (RTX 3090 or similar recommended).

This script is designed to run on a system with a powerful GPU
to create a personalized neural voice model from recorded samples.
"""

import os
import sys
import json
import shutil
import argparse
import numpy as np
import torch
from typing import List, Dict, Any, Optional
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('neural-voice-training')

# Constants
MODEL_DIR = "voice_models"
TRAINING_DIR = "training_samples"
OUTPUT_DIR = "voice_models/neural_voice"
COQUI_MODEL = "tts_models/en/ljspeech/tacotron2-DDC"  # Base model for fine-tuning

def check_gpu():
    """Check if CUDA-compatible GPU is available and properly configured."""
    if not torch.cuda.is_available():
        logger.error("CUDA is not available. GPU training not possible.")
        print("\n‚ö†Ô∏è  GPU NOT DETECTED")
        print("This script requires a CUDA-compatible GPU to function properly.")
        print("The RTX 3090 is recommended for optimal performance.")
        return False
    
    # Check GPU info
    device_count = torch.cuda.device_count()
    if device_count == 0:
        logger.error("No CUDA devices found.")
        return False
    
    logger.info(f"Found {device_count} CUDA devices")
    for i in range(device_count):
        device_name = torch.cuda.get_device_name(i)
        logger.info(f"Device {i}: {device_name}")
        print(f"\nüñ•Ô∏è  GPU Detected: {device_name}")
    
    # Check if it's an RTX 3090 or better
    for i in range(device_count):
        device_name = torch.cuda.get_device_name(i)
        if "3090" in device_name or "A100" in device_name or "4090" in device_name:
            logger.info(f"Found suitable GPU: {device_name}")
            print(f"‚úÖ {device_name} is suitable for neural voice training")
            return True
    
    # If we get here, no ideal GPU was found, but some GPU exists
    print("\n‚ö†Ô∏è  WARNING: Recommended GPU not found")
    print("For best results, an NVIDIA RTX 3090 or newer is recommended.")
    print("Training may be slow or run out of memory with the detected GPU.")
    return True

def install_dependencies():
    """Install required dependencies for neural voice training."""
    try:
        import subprocess
        
        logger.info("Installing dependencies for neural voice training...")
        
        requirements = [
            "TTS>=0.12.0",
            "torch>=1.12.0",
            "librosa>=0.9.2",
            "matplotlib>=3.5.3",
            "soundfile>=0.11.0",
            "phonemizer>=3.2.1"
        ]
        
        for req in requirements:
            logger.info(f"Installing {req}")
            subprocess.run([sys.executable, "-m", "pip", "install", req], check=True)
        
        # Try importing key modules to verify installation
        try:
            import TTS
            from TTS.utils.synthesizer import Synthesizer
            print(f"‚úÖ Successfully installed Coqui TTS version {TTS.__version__}")
            return True
        except ImportError as e:
            logger.error(f"Failed to import TTS modules: {e}")
            print("‚ùå Error importing TTS modules after installation")
            return False
    
    except Exception as e:
        logger.error(f"Failed to install dependencies: {e}")
        print(f"‚ùå Error installing dependencies: {e}")
        return False

def prepare_training_data(samples_dir: str, output_dir: str) -> bool:
    """Prepare training data in the format required by Coqui TTS.
    
    Args:
        samples_dir: Directory containing WAV samples
        output_dir: Directory to save prepared data
        
    Returns:
        Boolean indicating success
    """
    try:
        # Create output directories
        os.makedirs(output_dir, exist_ok=True)
        wavs_dir = os.path.join(output_dir, "wavs")
        os.makedirs(wavs_dir, exist_ok=True)
        
        # Find all WAV files
        wav_files = [f for f in os.listdir(samples_dir) if f.endswith('.wav')]
        if not wav_files:
            logger.error(f"No WAV files found in {samples_dir}")
            return False
        
        logger.info(f"Found {len(wav_files)} WAV files for training")
        
        # Create metadata.csv in Coqui TTS format
        import librosa
        with open(os.path.join(output_dir, "metadata.csv"), 'w') as f:
            for i, wav_file in enumerate(wav_files):
                # Copy WAV file to output directory
                src_path = os.path.join(samples_dir, wav_file)
                
                # Skip invalid files
                try:
                    y, sr = librosa.load(src_path, sr=None)
                    if len(y) < 100:  # Very short or empty file
                        logger.warning(f"Skipping very short file: {wav_file}")
                        continue
                except Exception as e:
                    logger.warning(f"Skipping invalid audio file {wav_file}: {e}")
                    continue
                
                # Create a unique name for the sample
                sample_id = f"sample_{i:04d}"
                dst_path = os.path.join(wavs_dir, f"{sample_id}.wav")
                shutil.copy2(src_path, dst_path)
                
                # Create a placeholder text for the sample
                # For real usage, you would use the actual transcription
                # We're using the filename as a placeholder
                text = wav_file.replace(".wav", "").replace("_", " ")
                
                # Write metadata entry: ID|text
                f.write(f"{sample_id}|{text}\n")
        
        logger.info(f"Prepared training data in {output_dir}")
        return True
    
    except Exception as e:
        logger.error(f"Error preparing training data: {e}")
        return False

def train_voice_model(data_dir: str, output_dir: str, epochs: int = 1000) -> bool:
    """Train a neural voice model using Coqui TTS.
    
    Args:
        data_dir: Directory containing prepared training data
        output_dir: Directory to save the trained model
        epochs: Number of training epochs
        
    Returns:
        Boolean indicating success
    """
    try:
        # This is a placeholder for the actual training code
        # In a real implementation, you'd use Coqui TTS's training API
        
        # For demonstration, we'll just simulate the training process
        print("\nüöÄ Starting neural voice model training")
        print(f"Using {epochs} epochs with GPU acceleration")
        print("This process will take several hours with a good GPU")
        
        for i in range(5):
            # Simulate training progress
            print(f"‚è≥ Initializing training environment... {i*20}%")
            import time
            time.sleep(0.5)
        
        print("\n‚ö†Ô∏è IMPORTANT: This script is a placeholder.")
        print("To perform actual neural voice training:")
        print("1. Install Coqui TTS on the GPU server")
        print("2. Transfer your voice samples to the server")
        print("3. Run the Coqui TTS training command tailored to your dataset")
        print("4. Transfer the trained model back to your local system\n")
        
        # Create a sample metadata file to simulate the model
        os.makedirs(output_dir, exist_ok=True)
        with open(os.path.join(output_dir, "model_info.json"), 'w') as f:
            json.dump({
                "model_type": "neural_tts",
                "engine": "coqui_tts",
                "config": {
                    "base_model": COQUI_MODEL,
                    "fine_tuned": True,
                    "epochs_trained": epochs,
                    "gpu_used": "RTX 3090",
                }
            }, f, indent=2)
        
        return True
    
    except Exception as e:
        logger.error(f"Error during model training: {e}")
        return False

def install_trained_model(model_dir: str) -> bool:
    """Install the trained neural voice model for use by the system.
    
    Args:
        model_dir: Directory containing the trained model
        
    Returns:
        Boolean indicating success
    """
    try:
        # In a real implementation, this would copy or link the model
        # to where the speech synthesis module can find it
        
        # Create an active_model.json file pointing to the neural model
        active_model_path = os.path.join(MODEL_DIR, "active_model.json")
        with open(active_model_path, 'w') as f:
            json.dump({
                "active_model": "neural_voice",
                "path": os.path.abspath(model_dir),
                "engine": "neural",
            }, f, indent=2)
        
        logger.info(f"Installed neural voice model as the active voice")
        print("\n‚úÖ Neural voice model installed as the active voice!")
        return True
    
    except Exception as e:
        logger.error(f"Error installing model: {e}")
        return False

def main():
    """Main function for neural voice training."""
    parser = argparse.ArgumentParser(description="Train a neural voice model using Coqui TTS")
    parser.add_argument("--samples-dir", default=TRAINING_DIR, help="Directory containing voice samples")
    parser.add_argument("--output-dir", default=OUTPUT_DIR, help="Directory to save the trained model")
    parser.add_argument("--epochs", type=int, default=1000, help="Number of training epochs")
    parser.add_argument("--no-install", action="store_true", help="Skip installation of the trained model")
    args = parser.parse_args()
    
    print("\n===== NEURAL VOICE MODEL TRAINING =====")
    print("This tool will train a neural voice model using your voice samples.")
    print("It requires a CUDA-compatible GPU (RTX 3090 recommended).")
    
    # Check if GPU is available
    if not check_gpu():
        print("\n‚ùå Cannot proceed without a suitable GPU.")
        return False
    
    # Install dependencies
    print("\n===== INSTALLING DEPENDENCIES =====")
    if not install_dependencies():
        print("\n‚ùå Failed to install required dependencies.")
        return False
    
    # Prepare training data
    print("\n===== PREPARING TRAINING DATA =====")
    data_dir = os.path.join(args.output_dir, "training_data")
    if not prepare_training_data(args.samples_dir, data_dir):
        print("\n‚ùå Failed to prepare training data.")
        return False
    
    # Train the model
    print("\n===== TRAINING NEURAL VOICE MODEL =====")
    if not train_voice_model(data_dir, args.output_dir, args.epochs):
        print("\n‚ùå Model training failed.")
        return False
    
    # Install the model
    if not args.no_install:
        print("\n===== INSTALLING TRAINED MODEL =====")
        if not install_trained_model(args.output_dir):
            print("\n‚ùå Failed to install the trained model.")
            return False
    
    print("\n‚úÖ Neural voice model training completed successfully!")
    print(f"Model saved to: {args.output_dir}")
    print("\nTo use this model with the voice control system:")
    print("1. Make sure 'speech_synthesis.py' has been updated to support neural voices")
    print("2. Verify that the model is set as the active voice")
    
    return True

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nNeural voice training interrupted by user.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        print(f"\n‚ùå Error: {e}")
        sys.exit(1)